{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685a8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mygrad as mg\n",
    "from mygrad.nnet.losses.margin_ranking_loss import margin_ranking_loss\n",
    "import mynn\n",
    "import numpy as np\n",
    "import re, string\n",
    "from collections import Counter\n",
    "\n",
    "from mygrad.nnet.initializers import glorot_normal\n",
    "from mynn.layers.dense import dense\n",
    "from mynn.optimizers.sgd import SGD\n",
    "from mynn.optimizers.adam import Adam\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4f79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(img_url: str) -> Image:\n",
    "    \"\"\"Fetches an image from the web.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_url : string\n",
    "        The url of the image to fetch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PIL.Image\n",
    "        The image.\"\"\"\n",
    "\n",
    "    response = requests.get(img_url)\n",
    "    return Image.open(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baeebaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    text: string\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Returns a list containing all the lower-cased versions of the words from the text parameter.\n",
    "    Each element is a word. All punctuation is removed. \n",
    "    Length of list = num words in text\n",
    "    \n",
    "    \"\"\"\n",
    "    punc_regex = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    return punc_regex.sub('', text).lower().split()\n",
    "\n",
    "def to_vocab(list_of_counters, k=None, stop_words=tuple()):\n",
    "    \"\"\" \n",
    "    [word, word, ...] -> sorted list of top-k unique words\n",
    "    Excludes words included in `stop_words`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_counters : Iterable[Iterable[str]]\n",
    "    \n",
    "    k : Optional[int]\n",
    "        If specified, only the top-k words are returned\n",
    "    \n",
    "    stop_words : Collection[str]\n",
    "        A collection of words to be ignored when populating the vocabulary\n",
    "    \"\"\"\n",
    "    # <COGINST>\n",
    "    vocab = Counter()\n",
    "    for counter in list_of_counters:\n",
    "        vocab.update(counter)\n",
    "        \n",
    "    for word in set(stop_words):\n",
    "        vocab.pop(word, None)  # if word not in bag, return None\n",
    "    return sorted(i for i,j in vocab.most_common(k))\n",
    "    # </COGINST>\n",
    "\n",
    "def phrase_idf(phrase_vocab, list_of_counters):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the IDF for the entire phrase. \n",
    "   \n",
    "    \"\"\"\n",
    "    N = len(list_of_counters)\n",
    "   \n",
    "    # if term i is not in glove, we set nt[i] = N that way its corresponding idf value is 0\n",
    "    nt = [sum(1 if term in counter else 0 for counter in list_of_counters) for term in phrase_vocab]\n",
    "    nt = np.array(nt, dtype=float)\n",
    "    \n",
    "    nt[nt == 0] = N\n",
    "    \n",
    "    \n",
    "    return np.log10(N / nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3d3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    def __init__(self):\n",
    "        self.ID_to_descriptor = resnet18_features\n",
    "        self.ID_to_URL = dict()\n",
    "        self.ID_to_captions = defaultdict(list) # key:value | ID --> list of captions corresonding to ID\n",
    "        self.ID_to_caption_embeddings = defaultdict(list) # key:value | ID --> list of caption embeddings corresonding to ID\n",
    "        # NOTE: USE \"glove\" TO CONVERT WORD --> WORD EMBEDDING\n",
    "        \n",
    "        # Getting ID --> URL:\n",
    "        for i in range(len(coco_data[\"images\"])):\n",
    "            ID = coco_data[\"images\"][i]['id']\n",
    "            URL = coco_data[\"images\"][i]['coco_url']\n",
    "            self.ID_to_URL[ID] = URL\n",
    "        \n",
    "        # Getting ID --> Captions\n",
    "        for i in range(len(coco_data[\"annotations\"])):\n",
    "            ID = coco_data[\"annotations\"][i]['image_id']\n",
    "            caption = coco_data[\"annotations\"][i]['caption']\n",
    "            self.ID_to_captions[ID].append(caption)\n",
    "        \n",
    "        # Initialize the dataset\n",
    "        self.make_dataset()\n",
    "        \n",
    "        # Shuffle datasets\n",
    "        self.shuffle_dataset()\n",
    "        \n",
    "        # Making List of caption_counters\n",
    "        all_caption_words = []\n",
    "        for ID in self.ID_to_captions:\n",
    "            for caption in self.ID_to_captions[ID]:\n",
    "                tokenized_caption = set(tokenize(caption))\n",
    "                for word in tokenized_caption:\n",
    "                    all_caption_words.append(word)\n",
    "\n",
    "        all_caption_words = sorted(all_caption_words)\n",
    "        \n",
    "        # Calculating all idfs and making word-->idf dict:\n",
    "        counter = Counter(all_caption_words)\n",
    "        N = len(coco_data[\"annotations\"])\n",
    "        words = list(counter.keys())\n",
    "\n",
    "        nt = list(counter.values())\n",
    "        nt = np.array(nt, dtype=float)\n",
    "        all_idfs = np.log10(N / nt)\n",
    "        self.idf_dict = {k:v for k, v in zip(words, all_idfs)}\n",
    "        \n",
    "        # Making ID --> Caption Embeddings\n",
    "        for i in range(len(coco_data[\"annotations\"])):\n",
    "            ID = coco_data[\"annotations\"][i]['image_id']\n",
    "            caption = coco_data[\"annotations\"][i]['caption']\n",
    "            self.ID_to_caption_embeddings[ID].append(self.parse_query(caption))\n",
    "    \n",
    "    # This funciton creates the dataset (only call this once during initialization process)\n",
    "    def make_dataset(self):\n",
    "        list_of_IDs = list(self.ID_to_descriptor.keys())\n",
    "        N = len(list_of_IDs)\n",
    "        self.dataset = np.zeros((N, 3), dtype=np.int64) # Shape: N, 3\n",
    "        \n",
    "        for i in range(N):\n",
    "            ID = list_of_IDs[i]\n",
    "            confuser_ID =list_of_IDs[random.randint(0, N-1)]\n",
    "            while ID == confuser_ID: # Just to make sure that the randomly picked confuser ID isn't the same as the img ID; 1/N chance of happening\n",
    "                confuser_ID = list_of_IDs[random.randint(0, N-1)]\n",
    "            caption_index = random.randint(0, len(self.ID_to_captions[ID])-1)\n",
    "            \n",
    "            self.dataset[i][0] = caption_index\n",
    "            self.dataset[i][1] = ID\n",
    "            self.dataset[i][2] = confuser_ID\n",
    "    \n",
    "    '''\n",
    "    This function randomly shuffles the dataset across its rows (each tuplet)\n",
    "    and makes the cuts for the training & validation sets;\n",
    "    call this when you want to shuffle the sets after each epoch.\n",
    "    '''\n",
    "    def shuffle_dataset(self):\n",
    "        np.random.shuffle(self.dataset)\n",
    "        cut = int(self.dataset.shape[0] * (4/5))\n",
    "        self.training_set = self.dataset[0:cut]\n",
    "        self.validation_set = self.dataset[cut:]\n",
    "    \n",
    "    # This function parses the query and returns one word embedding that represents the query\n",
    "    def parse_query(self, phrase):\n",
    "        phrase_vocab = to_vocab([Counter(tokenize(phrase))])\n",
    "\n",
    "        glove_embeddings = [(glove[term] if term in glove else np.zeros(200)) for term in phrase_vocab]\n",
    "        \n",
    "        idf = [ self.idf_dict[word] if word in self.idf_dict else 0 for word in phrase_vocab ] \n",
    "        \n",
    "\n",
    "       \n",
    "        w_phrase = sum( glove_embeddings[i] * idf[i] for i in range(len(idf)) )\n",
    "        \n",
    "\n",
    "        return w_phrase / np.sqrt((w_phrase ** 2).sum(keepdims=True)) # normalized\n",
    "    \n",
    "    # Call this function when model is trained; run it beofre you call \"get_k_most_similar_img_URLs\"\n",
    "    def make_img_embeddings(self, model):\n",
    "        self.img_embeddings = list()\n",
    "        with mg.no_autodiff:\n",
    "            for ID in self.ID_to_descriptor.keys():\n",
    "                self.img_embeddings.append(model(self.ID_to_descriptor[ID]).data)\n",
    "        self.img_embeddings = np.array(self.img_embeddings)\n",
    "    \n",
    "    # Function that takes in a string query and returns k most similar images in database. Returns most disimilar images if similar=False\n",
    "    def get_k_most_similar_img_URLs(self, query, k=1, similar=True):\n",
    "        query_embedding = self.parse_query(query)\n",
    "        results = self.img_embeddings @ query_embedding # (N, 200) dot (200, 1)\n",
    "        list_of_IDs = list(self.ID_to_descriptor.keys())\n",
    "        if similar:\n",
    "            results_sorted_indices = np.argsort(results, axis=0)[::-1]\n",
    "        else:\n",
    "            results_sorted_indices = np.argsort(results, axis=0)\n",
    "        kth_most_similar = results_sorted_indices[0:k].reshape(k,)\n",
    "        URLs = list()\n",
    "        captions = list()\n",
    "        for index in kth_most_similar:\n",
    "            URLs.append(self.ID_to_URL[list_of_IDs[index]])\n",
    "            captions.append(self.ID_to_captions[list_of_IDs[index]])\n",
    "        return URLs, captions\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a5015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(true_caption_img_similarity, conf_img_similarity):\n",
    "    \"\"\" Accuracy function for model training\"\"\"\n",
    "    diff = true_caption_img_similarity - conf_img_similarity\n",
    "    acc = np.mean(diff > 0)\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9c9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        \"\"\" This initializes all of the layers in our model, and sets them\n",
    "        as attributes of the model. \"\"\"\n",
    "        \n",
    "       \n",
    "        self.encoder = dense(512, 200, weight_initializer = glorot_normal, bias = False)\n",
    "        \n",
    "\n",
    "    def __call__(self, descriptor):\n",
    "       \n",
    "        '''Passes data as input to our model, performing a \"forward-pass\".\n",
    "        \n",
    "        This allows us to conveniently initialize a model `m` and then send data through it\n",
    "        to be classified by calling `m(x)`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Union[numpy.ndarray, mygrad.Tensor], shape=(M, D_full)\n",
    "            A batch of data consisting of M pieces of data,\n",
    "            each with a dimentionality of D_full.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(M, D_full)\n",
    "            The model's prediction for each of the M pieces of data.\n",
    "        '''\n",
    "        # keep in mind that this is a linear model - there is no \"activation function\"\n",
    "        # involved here\n",
    "        output = self.encoder(descriptor) \n",
    "        return output / np.sqrt((output ** 2).sum(keepdims=True, axis=1)) # normalized output\n",
    "        # N, 200 --> sum(axis 1) --> (N)\n",
    "        # N, 200 --> sum(axis 1, kpd=True) -->  broadcastable (N, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" A convenience function for getting all the parameters of our model.\n",
    "        \n",
    "        This can be accessed as an attribute, via `model.parameters` \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, ...]\n",
    "            A tuple containing all of the learnable parameters for our model \"\"\"\n",
    "        return self.encoder.parameters\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
